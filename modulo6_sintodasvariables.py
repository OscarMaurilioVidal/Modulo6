# -*- coding: utf-8 -*-
"""Modulo6_SinTodasVariables.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15nnd-62Q2AqnWeYWLkg9XhqzQT7-1gQe

**Ejercicio Análisis Módulo 6**

Carga de Librerías
"""

import numpy as np
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
import seaborn as sns

"""Carga de Base de datos

"""

datosCompletos = pd.read_csv('https://raw.githubusercontent.com/datagy/data/main/insurance.csv')

"""Exploración de datos"""

datosCompletos.head()

datosCompletos.shape

"""Validar si existen datos nulos"""

plt.figure(figsize = (12,4))
sns.heatmap(datosCompletos.isnull(), cbar=False, cmap='viridis', yticklabels=False)
plt.title('Valores faltantes en la base de datos')

"""**Transformación de variables categoricas**

Las variables smoker son variables catecoricas que hay que transformar para poder determinar su correlación
"""

#Analizando los posibles valores de las variables categoricas
fumadores = pd.unique(datosCompletos['smoker'])
fumadores

#sustituimos los valores que son binarios
datosCompletos['smoker'] = datosCompletos['smoker'].replace(['yes','no'],[1,0])
datosCompletos.head()

#Selecccionado solo las columnas que nos interesan
datos = datosCompletos.loc[:,['age','bmi','smoker','charges']]

"""Correlación tomando en cuenta solo smoker como variable categorica

Se puede ver que la corrrelación entre las variables sex y charges es muy pequeña por lo cual podemos omitirla del modelo, al igual que la correlación entre children y charges, lo mismo sucede con region y charges

Las variables que tienen una fuerte correlación con charges son: age, bmi, smoker
"""

datos.corr()

"""En el mapa de calor se puede ver que la correlación más que tiene charges es smoker"""

import seaborn as sns
sns.heatmap(datos.corr().abs())
plt.show()

"""**Graficas de correlación**"""

sm = scatter_matrix(datos, figsize=(15,15), diagonal = 'kde')
#rotación de etiquetas
[s.xaxis.label.set_rotation(0) for s in sm.reshape(-1)]
[s.yaxis.label.set_rotation(90) for s in sm.reshape(-1)]
#etiqueta de salida
[s.get_yaxis().set_label_coords(-0.1,0.5) for s in sm.reshape(-1)]
#quitar numeros
[s.set_xticks(()) for s in sm.reshape(-1)]
[s.set_yticks(()) for s in sm.reshape(-1)]
plt.show()

"""**Mostrando las distribuciones, destacando la variable smoker**

"""

sns.pairplot(datos, hue = 'smoker')
plt.show

"""**Mostrando las distribuciones, destacando la variable age**

"""

sns.pairplot( datos, hue = 'age' )
plt.show

"""**Mostrando las distribuciones, destacando la variable bmi**"""

sns.pairplot(datos, hue = 'bmi' )
plt.show

"""Por la gráfica se ve que los cargos aumentan si eres fumador e incrementa la edad"""

sns.relplot(data=datos, x= 'age', y = 'charges', hue = 'smoker')

"""Se puede ver que el ser fumador es un factor más determinante para aumentar los cargos que la masa muscular"""

sns.relplot(data=datos, x= 'bmi', y = 'charges', hue = 'smoker')



"""**Módelo de regresión lineal para Charges**"""

def R2Ad(r2,n,k):
  Ad = 1-((1-r2)*((n-1)/(n-k-1)))
  return Ad

"""**Dividar bd en entrenamiento y prueba**"""

#Dividar bd en entrenamiento y prueba
from sklearn.model_selection import train_test_split
train, test = train_test_split(datos, test_size=0.2)

train_x = train.loc[:, train.columns != 'charges']
test_x = test.loc[:, test.columns != 'charges']

train_y = train['charges']
test_y = test['charges']

train.head()

train_x.head()

train_y.head()

#Escalando los datos
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler().fit(train_x)
x_train_scaled = pd.DataFrame(scaler.transform(train_x), columns = train_x.columns)
x_train_scaled.head()
x_test_scaled = pd.DataFrame(scaler.transform(test_x), columns = test_x.columns)

x_train_scaled.head()

"""Generando el modelo"""

model = linear_model.LinearRegression()

"""Se ajusta el modelo multivariable."""

model.fit(x_train_scaled, train_y)

"""Recuperando coeficientes(w) de cada parámetro del modelo"""

print(model.coef_)

#Ya que se entreno se predice con nuevos valores a que debe llegar el moedlo, y se utilizan los valores de prueba.
#test_pred es una lista de valores pronosticados en base a unos datos no utilizados previamente.

test_pred = model.predict(x_test_scaled)

#Diferencia cuadratica media entre el valor calculado y el valor real, entre más cerca a cero es más efectivo el modelo

mean_squared_error(test_y, test_pred)

#Se calcula la r cuadrada, mientras más se acerque a uno mejor.

r2 = r2_score(test_y, test_pred)
print (r2)

n, k = np.shape(x_test_scaled)
#n, son las filas observadas
#k las variables predictoraas o numero de columnas para determinar Charge, es decir la longitud de número de variables

#R ajustada
 R2Ad(r2,n,k)

"""**Regresión Ridge**"""

from sklearn.linear_model import  Ridge, Lasso

Rd = Ridge()
model = Rd.fit(x_train_scaled, train_y)
y_predict = model.predict(x_test_scaled)
print('r2', r2_score(test_y, y_predict))
r2 = r2_score(test_y, y_predict)
n, k = np.shape(x_test_scaled)
print('r2_ad', R2Ad(r2,n,k) )

"""**Lasso**"""

Ls = Lasso()
model = Ls.fit(x_train_scaled, train_y)
y_predict = model.predict(x_test_scaled)
print(r2_score(test_y, y_predict))
r2 = r2_score(test_y, y_predict)
n, k = np.shape(x_test_scaled)
print('r2_ad', R2Ad(r2,n,k) )

"""**KNN**"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error
from sklearn.model_selection import KFold, cross_val_score

n_neighbors = 5

for i, weights in enumerate(["uniform", "distance"]):
    knn = KNeighborsRegressor(n_neighbors, weights=weights)
    model = knn.fit(x_train_scaled, train_y)
    y_predict = model.predict(x_test_scaled)
    print('n_neighbors', n_neighbors)
    print('weights',weights)
    print(r2_score(test_y, y_predict))

n_neighbors = 5
for k in np.arange(1,7):
    knn = KNeighborsRegressor(n_neighbors = k, weights="uniform")
    y_predict = knn.fit(x_train_scaled, train_y).predict(x_test_scaled)
    n, ki = np.shape(x_test_scaled)    
    print('n_neighbors', k)
    r2 = r2_score(test_y, y_predict)
    print('r2', r2)
    print('r2_ad', R2Ad(r2,n,ki) )



Model = []
RMSE = []
R_sq = []
cv = KFold(5)
MAPE = []

#Creating a Function to append the cross validation scores of the algorithms
def input_scores(name, model, x, y):
    Model.append(name)
    RMSE.append(np.sqrt((-1) * cross_val_score(model, x, y, cv=cv, 
                                               scoring='neg_mean_squared_error').mean()))
    R_sq.append(cross_val_score(model, x, y, cv=cv, scoring='r2').mean())

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, 
                              AdaBoostRegressor)

names = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',
         'K Neighbors Regressor', 'Decision Tree Regressor', 
         'Random Forest Regressor', 'Gradient Boosting Regressor',
         'Adaboost Regressor']
models = [LinearRegression(), Ridge(), Lasso(),
          KNeighborsRegressor(), DecisionTreeRegressor(),
          RandomForestRegressor(), GradientBoostingRegressor(), 
          AdaBoostRegressor()]

#Running all algorithms
for name, model in zip(names, models):
    input_scores(name, model, x_train_scaled, train_y)

R_sq_ad = []
for Rs in R_sq:
  R_sq_ad.append(R2Ad(Rs,n,k))

evaluation = pd.DataFrame({'Model': Model,
                           'RMSE': RMSE,
                           'R Squared': R_sq,
                           'R2_ad':R_sq_ad})
print("FOLLOWING ARE THE TRAINING SCORES: ")
evaluation